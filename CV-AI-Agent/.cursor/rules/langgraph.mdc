---
description: Specific rules for implementing LangGraph with Gemini, including RAG and state management, for the Application Factory.
globs: 
alwaysApply: false
---
# LangGraph & Gemini Implementation Rules (Application Factory)

## Core Technologies
- **LangGraph:** For orchestrating the multi-step generation process. [6, 11, 33, 46, 47]
- **Google Gemini LLM:** As the core language model for text generation and analysis (via API).
- **RAG (Retrieval Augmented Generation):**
    - For Master Resume and Job Description (both PDF inputs).
    - PDF Parsing: `PyPDF2` or `pdfminer.six`.
    - Text Chunking: LangChain's `RecursiveCharacterTextSplitter`.
    - Embeddings: Google's `text-embedding-004` (or latest compatible).
    - Vector Store: FAISS (local) or ChromaDB.
- Document Generation: `python-docx` for creating `.docx` from the examples in `Example CV/` check for templates of these based on files, then `docx2pdf` for PDF conversion.

## LangGraph Design [6, 11, 47]
- **State Management:**
    - Define a clear Pydantic model or TypedDict for the graph's state for both Resume and Cover Letter generation flows. [6]
    - The state should include all necessary data passed between nodes (e.g., retrievers, user info, generated text sections, feedback notes, iteration history).
    - Nodes should return new state objects, not modify existing state in-place (if possible, to maintain functional purity). [6]
- **Nodes:**
    - Each node should have a single, well-defined responsibility (e.g., "generate_summary_node", "extract_header_info_node"). [6, 11]
    - Implement robust error handling within each node. Log errors and update graph state with error messages if necessary. [6, 11]
    - Node functions will primarily interact with the Gemini LLM, RAG retrievers, and format outputs.
- **Edges:**
    - Define clear conditional logic for edges, especially for iterative parts like cover letter refinement. [6]
- **LLM Prompts (`core/llm_prompts.py`):**
    - All prompts for Gemini must be stored and managed in `core/llm_prompts.py`.
    - Prompts must be detailed and instruct the LLM on its role, the context, the specific task, and the desired output format (e.g., JSON for structured data extraction).
    - For resume/cover letter section generation, prompts must explicitly instruct the LLM to:
        - Adhere to a one-page limit for the final document.
        - Use ONLY information present in the master resume for factual content (especially projects and experience); no making things up.
        - Tailor content to the specifics of the job description.
        - Integrate keywords naturally.
- **RAG Implementation (`core/rag_processor.py`):**
    - Function `load_and_process_pdf`: Takes PDF path, extracts text, chunks, creates embeddings, and returns a retriever (FAISS or Chroma).
    - This retriever will be used by LangGraph nodes to fetch relevant context from the master resume and job description.
- **Header Information Extraction:**
    - A dedicated LangGraph node (`extract_header_info_node`) will use the raw text of the master resume and a Gemini prompt to extract: Name, Location, Email, Phone, LinkedIn URL, Portfolio Website URL (optional).
    - Output must be a structured dictionary.

## DOCX Templating (`core/document_generator.py`) [Specific to Technical Blueprint]
- **`populate_resume_template` and `populate_cl_template` functions:**
    - These functions MUST use `python-docx` to open `resume_template.docx` and `cover_letter_template.docx` from the `Example CV/` folder.
    - They will replace defined placeholders (e.g., `{{SUMMARY_CONTENT}}`, `{{PROJECT_TITLE}}`) in the templates with data generated by the LLM and extracted header info.
    - **Ensure the generated DOCX visually matches the formatting of the `Example CV/` templates EXACTLY.** This includes fonts, spacing, margins, bullet styles, etc. The templates are the source of truth for formatting.
- **`convert_docx_to_pdf` function:**
    - Uses `docx2pdf` to convert the populated DOCX file to PDF.
    - Handle potential conversion errors gracefully.

## Specific User Journey Implementation (Resume Builder)
1.  **Initial Generation & Preview:**
    *   Run resume generation graph.
    *   Populate DOCX template, convert to PDF.
    *   Display PDF preview in Streamlit (`st.pdf()`).
2.  **Editing:**
    *   If user clicks "Edit Resume":
        *   Display ALL generated sections (summary, skills, etc.) in `st.text_area` widgets ON THE SAME STREAMLIT PAGE.
        *   User edits text.
        *   "Save Changes & Update Preview" button:
            *   Takes edited text.
            *   Re-runs `populate_resume_template` and `convert_docx_to_pdf`.
            *   Updates the `st.pdf()` preview.
3.  **Finalize:**
    *   "Finalize Resume & Continue to Cover Letter" button saves the state and moves to the next stage.

## Specific User Journey Implementation (Cover Letter Builder)
1.  **Intro/Conclusion Iteration:**
    *   Generate initial intro/conclusion.
    *   Display in `st.text_area`s.
    *   User can directly edit OR provide notes in a separate `st.text_area` for "Feedback/Notes".
    *   "Regenerate Intro/Conclusion" button re-runs the relevant LangGraph node, passing current text and feedback notes.
    *   Store previous versions for a "Go Back" functionality.
2.  **Body Paragraph Iteration:** Similar iterative process for body paragraphs.
3.  **Preview:** "Preview Cover Letter" button at any stage populates DOCX from current edited/generated sections and shows PDF.
4.  **Finalize:** Saves state and documents.

## Gemini API Usage
- Ensure all calls to the Gemini API are made through the LangChain integration (`ChatGoogleGenerativeAI` or `GoogleGenerativeAIEmbeddings`).
- Handle API errors (e.g., rate limits, authentication issues) gracefully.
- Structure prompts to maximize Gemini's capabilities for tailoring and generation while adhering to constraints (e.g., one-page limit, no fabrication).


